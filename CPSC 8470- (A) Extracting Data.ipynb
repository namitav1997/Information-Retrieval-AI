{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook retrieves and parses all the information from the four categories.\n",
    "\n",
    "(Includes bbox if the information exists)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pwd = os.getcwd()\n",
    "\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_path = '/Category and Attribute Prediction Benchmark'\n",
    "consumer_path = '/Consumer-to-shop Clothes Retrieval Benchmark'\n",
    "landmark_path = '/Fashion Landmark Detection Benchmark'\n",
    "inshop_path = '/In-shop Clothes Retrieval Benchmark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = pwd + '/Data/All/'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Category and Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_directory = pwd + category_path\n",
    "data_path = cat_directory + '/Img/'\n",
    "bbox_path = cat_directory + '/Anno/list_bbox.txt'\n",
    "img_category_path = cat_directory + '/Anno/list_category_img.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 289222/289222 [00:02<00:00, 141440.34it/s]\n"
     ]
    }
   ],
   "source": [
    "img_bbox = {}\n",
    "\n",
    "try:\n",
    "    bbox_file = open(bbox_path, 'r')\n",
    "except Exception:\n",
    "    print 'get_bbox() error'\n",
    "    \n",
    "bbox_data = bbox_file.readlines()\n",
    "for d, i in tqdm(zip(bbox_data[2:],range(bbox_data.__len__()-2))):\n",
    "    s = d.split()\n",
    "    p = data_path + s[0]\n",
    "    bbox_loca = []\n",
    "    for a in s[1:]:\n",
    "        bbox_loca.append(int(a))\n",
    "    img_bbox[p] = bbox_loca\n",
    "bbox_file.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 289222/289222 [00:00<00:00, 368510.73it/s]\n"
     ]
    }
   ],
   "source": [
    "img_category = {}\n",
    "\n",
    "#count_1 = 0\n",
    "#count_2 = 0\n",
    "#count_3 = 0\n",
    "\n",
    "try:\n",
    "    img_category_file = open(img_category_path, 'r')\n",
    "except Exception:\n",
    "    print 'img_category_path error!!'\n",
    "lines = img_category_file.readlines()\n",
    "for l in tqdm(lines[2:]):\n",
    "    s = l.split()\n",
    "    path = data_path + s[0]\n",
    "    \n",
    "    s[1] = int(s[1])\n",
    "    \n",
    "    # 1~20 is (1), 21~36 is (2), 37~50 is (3)\n",
    "    if s[1] < 21 :\n",
    "        img_category[path] = 1\n",
    "        #count_1 += 1\n",
    "    elif s[1] > 36 :\n",
    "        img_category[path] = 3\n",
    "        #count_3 += 1\n",
    "    else :\n",
    "        img_category[path] = 2\n",
    "        #count_2 += 1\n",
    "\n",
    "#print count_1\n",
    "#print count_2\n",
    "#print count_3\n",
    "#print count_1 + count_2 + count_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "289222it [00:01, 199809.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# merge dictionaries together\n",
    "\n",
    "ds = [img_bbox, img_category]\n",
    "d = {}\n",
    "for k in tqdm(img_bbox.iterkeys()):\n",
    "    d[k] = tuple(d[k] for d in ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "289222it [00:01, 160123.00it/s]\n"
     ]
    }
   ],
   "source": [
    "line = \"\"\n",
    "f = open(output_path + 'd-category-all.txt', 'w')\n",
    "for key,value in tqdm(d.iteritems()):\n",
    "    line = str(key)\n",
    "    for v in value:\n",
    "        if type(v) == list:\n",
    "            for point in v:\n",
    "                line += \": \" + str(point)\n",
    "        else:\n",
    "            line += \": \" + str(v) + '\\n'\n",
    "            \n",
    "    if int(line.split(\":\")[-1]) < 3 :\n",
    "        f.write(line)\n",
    "    \n",
    "bbox_file.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Consumer-to-shop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con_directory = pwd + consumer_path\n",
    "data_path = con_directory + '/Img/'\n",
    "bbox_path = con_directory + '/Anno/list_bbox_consumer2shop.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239557/239557 [00:01<00:00, 194167.61it/s]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    bbox_file = open(bbox_path, 'r')\n",
    "except Exception:\n",
    "    print 'get_bbox() error'\n",
    "bbox_data = bbox_file.readlines()\n",
    "f = open(output_path + 'd-consumer-all.txt', 'w')\n",
    "\n",
    "\n",
    "for d, i in tqdm(zip(bbox_data[2:],range(bbox_data.__len__()-2))):\n",
    "    s = d.split()\n",
    "    p = data_path + s[0]\n",
    "\n",
    "    line = str(p)\n",
    "\n",
    "    for point in s[3:]:\n",
    "        line += \": \" + point\n",
    "    line += ': ' + s[1] + '\\n'\n",
    "\n",
    "    if int(line.split(\":\")[-1]) < 3 :\n",
    "        f.write(line)\n",
    "\n",
    "bbox_file.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### For Fashion Landmark Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "land_directory = pwd + landmark_path\n",
    "data_path = land_directory + '/Img/'\n",
    "bbox_path = land_directory + '/Anno/list_bbox.txt'\n",
    "img_landmark_path = land_directory + '/Anno/list_landmarks.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123016/123016 [00:01<00:00, 117513.66it/s]\n"
     ]
    }
   ],
   "source": [
    "img_bbox = {}\n",
    "\n",
    "try:\n",
    "    bbox_file = open(bbox_path, 'r')\n",
    "except Exception:\n",
    "    print 'get_bbox() error'\n",
    "    \n",
    "bbox_data = bbox_file.readlines()\n",
    "for d, i in tqdm(zip(bbox_data[2:],range(bbox_data.__len__()-2))):\n",
    "    s = d.split()\n",
    "    p = data_path + s[0]\n",
    "    bbox_loca = []\n",
    "    for a in s[1:]:\n",
    "        bbox_loca.append(int(a))\n",
    "    img_bbox[p] = bbox_loca\n",
    "bbox_file.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123016/123016 [00:00<00:00, 363539.74it/s]\n"
     ]
    }
   ],
   "source": [
    "img_landmark = {}\n",
    "try:\n",
    "    img_landmark_file = open(img_landmark_path, 'r')\n",
    "except Exception:\n",
    "    print 'img_landmark_path error!!'\n",
    "lines = img_landmark_file.readlines()\n",
    "for l in tqdm(lines[2:]):\n",
    "    s = l.split()\n",
    "    path = data_path + s[0]\n",
    "    \n",
    "    img_landmark[path] = s[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123016it [00:00, 275535.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# merge dictionaries together\n",
    "\n",
    "ds = [img_bbox, img_landmark]\n",
    "d = {}\n",
    "for k in tqdm(img_bbox.iterkeys()):\n",
    "    d[k] = tuple(d[k] for d in ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123016it [00:00, 162685.76it/s]\n"
     ]
    }
   ],
   "source": [
    "line = \"\"\n",
    "f = open(output_path + 'd-landmark-all.txt', 'w')\n",
    "for key,value in tqdm(d.iteritems()):\n",
    "    line = str(key)\n",
    "    for v in value:\n",
    "        if type(v) == list:\n",
    "            for point in v:\n",
    "                line += \": \" + str(point)\n",
    "        else:\n",
    "            line += \": \" + str(v) + '\\n'\n",
    "            \n",
    "    if int(line.split(\":\")[-1]) < 3 :\n",
    "        f.write(line)\n",
    "    \n",
    "bbox_file.close()\n",
    "f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For In-shop Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inshop_directory = pwd + inshop_path\n",
    "data_path = inshop_directory + '/Img/'\n",
    "bbox_path = inshop_directory + '/Anno/list_bbox_inshop.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52712/52712 [00:00<00:00, 195383.02it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    bbox_file = open(bbox_path, 'r')\n",
    "except Exception:\n",
    "    print 'get_bbox() error'\n",
    "bbox_data = bbox_file.readlines()\n",
    "f = open(output_path + 'd-inshop-all.txt', 'w')\n",
    "\n",
    "\n",
    "for d, i in tqdm(zip(bbox_data[2:],range(bbox_data.__len__()-2))):\n",
    "    s = d.split()\n",
    "    path = data_path + s[0]\n",
    "\n",
    "    line = str(path)\n",
    "\n",
    "    for point in s[3:]:\n",
    "        line += \": \" + point\n",
    "    line += ': ' + s[1] + '\\n'\n",
    "    \n",
    "    if int(line.split(\":\")[-1]) < 3 :\n",
    "        f.write(line)\n",
    "\n",
    "bbox_file.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/DeepFashion/DeepFashion/In-shop Clothes Retrieval Benchmark/Anno/list_bbox_inshop.txt\n"
     ]
    }
   ],
   "source": [
    "print bbox_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
